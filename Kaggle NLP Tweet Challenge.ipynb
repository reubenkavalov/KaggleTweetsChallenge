{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_char'] = df['text'].apply(lambda x: len(x))\n",
    "df['num_words'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling in Keyword Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab all #hashtags in a list\n",
    "df.loc[df['keyword'].isna(),'hashtags'] = df['text'].apply(lambda x: [i[1:] for i in x.split() if '#' in i])\n",
    "\n",
    "#create a set of all values in keyword column\n",
    "keywords = set(df[~df.keyword.isna()].keyword.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrow down the list list of all hashtags in keywords\n",
    "df['new_tag'] = df.hashtags.apply(lambda x: [i.lower() for i in x if i in keywords] if type(x) == list else np.nan)\n",
    "\n",
    "#drop empty lists\n",
    "df['new_tag'] = df['new_tag'].apply(lambda x: x if x != [] and x != np.nan else np.nan)\n",
    "\n",
    "#grab the first hashtag and fill in missing values\n",
    "df['new_tag'] = df['new_tag'].apply(lambda x: x[0] if type(x) == list else np.nan)\n",
    "df.loc[df.keyword.isna(), 'keyword'] = df['new_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop old columns\n",
    "df.drop(['new_tag','hashtags'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Weird Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of weird characters and blank spaces\n",
    "characters= ['?','/', '#','+']\n",
    "df['location'] = df.location.apply(lambda x: x if not any([char in str(x) for char in characters]) else np.nan)\n",
    "df['location'] = df.location.apply(lambda x: x if type(x) != str else (x if x.strip() != '' else np.nan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of locations with numbers\n",
    "df['location'] = df.location.apply(lambda x: x if not any([i.isdigit() for i in str(x)]) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of locations with 4 or more words\n",
    "df['location'] = df.location.apply(lambda x: x if type(x) != str else (x if len(x.split()) < 4 else np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_abbrev_and_words = ['Earth','Worldwide','Everywhere','Reddit','World','Global','ava','EIC','HTX', 'ATX','atx','PDX','MNL','CLT', 'NBO', 'AEP','mnl', 'ayr', 'GCC', 'Htx','wny', 'VCU', 'Orm', 'DMV','Ktx',]\n",
    "df['location'] = df.location.apply(lambda x: x if x not in bad_abbrev_and_words else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.groupby('location').location.transform('count') == 1,'location'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling in Location Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into two differnt columns for upper case abbreviations and lower case for words\n",
    "df['new_loc_lower'] = df.text.apply(lambda x: [i.lower().strip() for i in x.split() if len(i) > 2])\n",
    "df['new_loc_upper'] = df.text.apply(lambda x: [i.upper().strip() for i in x.split() if len(i) <= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all blank strings from both\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: x if '' not in x else np.nan)\n",
    "df['new_loc_upper'] = df.new_loc_upper.apply(lambda x: x if '' not in x else np.nan)\n",
    "\n",
    "#remove all empty lists from both\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: x if x != [] else np.nan)\n",
    "df['new_loc_upper'] = df.new_loc_upper.apply(lambda x: x if x != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a unique list of locations for both upper and lower\n",
    "x = list(df.location.unique())[1:]\n",
    "key_down = [i.lower() for i in x if len(i) > 2]\n",
    "key_up = [i.upper() for i in x if len(i) <= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all words that arnt in either key_up or key_down\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: [i.lower() for i in x if i.lower() in key_down] if type(x) == list else np.nan)\n",
    "df['new_loc_upper'] = df.new_loc_upper.apply(lambda x: [i.upper() for i in x if i.upper() in key_up] if type(x) == list else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove common 2 letter words from initials\n",
    "bad_initials = ['IN','ON', 'OK']\n",
    "df['new_loc_upper'] = df.new_loc_upper.apply(lambda x: [i for i in x if i not in bad_initials] if type(x) == list else np.nan)\n",
    "\n",
    "#remove empty lists and grab the first element in each list\n",
    "df['new_loc_upper'] = df.new_loc_upper.apply(lambda x: x if x != [] else np.nan)\n",
    "df['new_loc_upper'] = df.new_loc_upper.apply(lambda x: x[0] if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty lists\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: x if x != [] else np.nan)\n",
    "\n",
    "#if only element in list grab that element\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: x if type(x) != list else (x[0] if len(x) == 1 else x))\n",
    "\n",
    "#if element repeats in list grab that element\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: x if type(x) != list else (x[0] if x[0] in x[1:] else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_places = ['west','east','north','south', 'mass', 'hell','heaven', 'global','world', 'unknown', 'earth', 'ebola', 'nowhere','studio', 'lincoln']\n",
    "\n",
    "#remove all words in bad_places for lists\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: [i for i in x if i not in bad_places] if type(x) == list else x)\n",
    "\n",
    "#remove all words in bad_places for strings\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: x if type(x) != str else(x if x not in bad_places else np.nan))\n",
    "\n",
    "#set empty lists to NaN and grab the first element in each list\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: x if x != [] else np.nan)\n",
    "df['new_loc_lower'] = df.new_loc_lower.apply(lambda x: x[0] if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set 2 digit location first since more common, then words\n",
    "df.loc[df['location'].isna(),'location'] = df.loc[df['location'].isna(),'new_loc_upper']\n",
    "df.loc[df['location'].isna(),'location'] = df.loc[df['location'].isna(),'new_loc_lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['new_loc_lower','new_loc_upper'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.groupby('location').location.transform('count') == 1, 'location'] = 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the second location in each location with two specified\n",
    "df['location'] = df['location'].apply(lambda x: x if type(x) != str else x.split(', ')[1] if ', ' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing .\n",
    "df['location'] = df['location'].apply(lambda x: x if type(x) != str else  ''.join(x.split('.')) if '.' in x else x)\n",
    "\n",
    "#capitalize \n",
    "df['location'] = df['location'].apply(lambda x: x.title() if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.groupby('location').location.transform('count') < 11,'location'] = 'ten_or_less'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.location.fillna('Missing', inplace=True)\n",
    "df.keyword.fillna('Missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``', 'http', 'https']\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    tokenized_tweet = nltk.word_tokenize(tweet)\n",
    "    clean_results = [w.lower() for w in tokenized_tweet if not w.lower() in stopwords_list and not 't.co/' in w.lower()]\n",
    "    return clean_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = list(map(process_tweet, df.text))\n",
    "df['tokenized_text'] = processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18443"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_vocab = set()\n",
    "for i in processed_data:\n",
    "    total_vocab.update(i)\n",
    "len(total_vocab)\n",
    "total_wordcount = len(total_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_concat = []\n",
    "for i in processed_data:\n",
    "    tweets_concat+=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'s\", 791),\n",
       " (\"n't\", 446),\n",
       " ('like', 345),\n",
       " ('amp', 344),\n",
       " (\"'m\", 250),\n",
       " ('fire', 249),\n",
       " ('get', 228),\n",
       " ('new', 219),\n",
       " ('via', 218),\n",
       " ('people', 197),\n",
       " ('news', 197),\n",
       " ('one', 194),\n",
       " ('video', 165),\n",
       " ('2', 162),\n",
       " ('emergency', 155),\n",
       " ('disaster', 153),\n",
       " ('would', 141),\n",
       " ('police', 138),\n",
       " (\"'re\", 129),\n",
       " ('still', 128)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_freqdist = FreqDist(tweets_concat)\n",
    "tweets_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.target\n",
    "features = df.drop(columns=['target','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test = train_test_split(features,target,test_size = 0.2,random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>length_of_tweet</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>injured</td>\n",
       "      <td>USA</td>\n",
       "      <td>Offers : http://t.co/Gl3C1vc88P #8392 Deluxe T...</td>\n",
       "      <td>139</td>\n",
       "      <td>[offers, 8392, deluxe, toilet, safety, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>hurricane</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The hurricane mixxtail kinda tastes like the w...</td>\n",
       "      <td>87</td>\n",
       "      <td>[hurricane, mixxtail, kinda, tastes, like, wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>hijacker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete Solution to Get Rid of http://t.co/9C...</td>\n",
       "      <td>117</td>\n",
       "      <td>[complete, solution, get, rid, ûò, browser, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>hellfire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@HellFire_eV @JackPERU1 then I do this to one ...</td>\n",
       "      <td>58</td>\n",
       "      <td>[hellfire_ev, jackperu1, one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>39</td>\n",
       "      <td>[flood, bago, myanmar, arrived, bago]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        keyword location                                               text  \\\n",
       "4549    injured      USA  Offers : http://t.co/Gl3C1vc88P #8392 Deluxe T...   \n",
       "4512  hurricane      NaN  The hurricane mixxtail kinda tastes like the w...   \n",
       "4368   hijacker      NaN  Complete Solution to Get Rid of http://t.co/9C...   \n",
       "4297   hellfire      NaN  @HellFire_eV @JackPERU1 then I do this to one ...   \n",
       "13          NaN      NaN            #Flood in Bago Myanmar #We arrived Bago   \n",
       "\n",
       "      length_of_tweet                                     tokenized_text  \n",
       "4549              139  [offers, 8392, deluxe, toilet, safety, support...  \n",
       "4512               87  [hurricane, mixxtail, kinda, tastes, like, wat...  \n",
       "4368              117  [complete, solution, get, rid, ûò, browser, h...  \n",
       "4297               58                      [hellfire_ev, jackperu1, one]  \n",
       "13                 39              [flood, bago, myanmar, arrived, bago]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data_train = vectorizer.fit_transform(X_train.text)\n",
    "\n",
    "tf_idf_data_test = vectorizer.transform(X_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 18449)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Tweets: 14.652709359605911\n",
      "Percentage of columns containing 0: 0.9992057721632822\n"
     ]
    }
   ],
   "source": [
    "non_zero_cols = tf_idf_data_train.nnz / float(tf_idf_data_train.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Tweets: {}\".format(non_zero_cols))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / float(tf_idf_data_train.shape[1]))\n",
    "print('Percentage of columns containing 0: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['tokenized_text','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length_of_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword location                                               text  \\\n",
       "0  earthquake      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1         NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2         NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3         NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4         NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  length_of_tweet  \n",
       "0       1               69  \n",
       "1       1               38  \n",
       "2       1              133  \n",
       "3       1               65  \n",
       "4       1               88  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "nb_classifier.fit(tf_idf_data_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_data_train)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(tf_idf_data_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_data_train)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Training Accuracy: 0.8892 \t\t Testing Accuracy: 0.7912\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest\n",
      "Training Accuracy: 0.9969 \t\t Testing Accuracy: 0.7781\n"
     ]
    }
   ],
   "source": [
    "nb_train_score = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_score = accuracy_score(y_test, nb_test_preds)\n",
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))\n",
    "print(\"\")\n",
    "print('-'*70)\n",
    "print(\"\")\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts= cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, df['target'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reuben/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7810858143607706\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "predicted= rf_clf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer()\n",
    "text_tf = tf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_tf, df['target'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.7964098073555166\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"MultinomialNB Accuracy:\", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\" : [1, 3, 6, 9],\n",
    "    \"n_estimators\" : [10, 30, 100, 150, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 78.06%\n",
      "Total Runtime for Grid Search on Random Forest Classifier: 3.172e+03 seconds\n",
      "\n",
      "Optimal Parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rf_grid_search = GridSearchCV(rf_clf,rf_param_grid,cv=3)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Testing Accuracy: {:.4}%\".format(rf_grid_search.best_score_ * 100))\n",
    "print(\"Total Runtime for Grid Search on Random Forest Classifier: {:.4} seconds\".format(time.time() - start))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(rf_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score for AdaBoost: 73.02%\n"
     ]
    }
   ],
   "source": [
    "adaboost_clf = AdaBoostClassifier()\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "adaboost_mean_cv_score = np.mean(cross_val_score(adaboost_clf,X_train,y_train,cv=3))\n",
    "\n",
    "print(\"Mean Cross Validation Score for AdaBoost: {:.4}%\".format(adaboost_mean_cv_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 250],\n",
    "    \"learning_rate\": [1.0, 0.5, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 75.55%\n",
      "Total Runtime for Grid Search on AdaBoost: 854.7 seconds\n",
      "\n",
      "Optimal Parameters: {'learning_rate': 0.5, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "adaboost_grid_search = GridSearchCV(adaboost_clf,adaboost_param_grid,cv=3)\n",
    "adaboost_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Testing Accuracy: {:.4}%\".format(adaboost_grid_search.best_score_ * 100))\n",
    "print(\"Total Runtime for Grid Search on AdaBoost: {:.4} seconds\".format(time.time() - start))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(adaboost_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['text'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    tokenized_tweet = nltk.word_tokenize(tweet)\n",
    "    clean_results = [w.lower() for w in tokenized_tweet if not w.lower() in stopwords_list and not 't.co/' in w.lower()]\n",
    "    return clean_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27285 unique tokens in the dataset.\n"
     ]
    }
   ],
   "source": [
    "total_vocabulary = set(word for headline in data for word in headline)\n",
    "print(\"There are {} unique tokens in the dataset.\".format(len(total_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "    # Note from Mike: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "    # It can't be used in a sklearn Pipeline. \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf =  Pipeline([(\"Word2Vec Vectorizer\", W2vVectorizer(glove)),\n",
    "              (\"Random Forest\", RandomForestClassifier(n_estimators=100, verbose=True))])\n",
    "svc = Pipeline([(\"Word2Vec Vectorizer\", W2vVectorizer(glove)),\n",
    "                ('Support Vector Machine', SVC())])\n",
    "lr = Pipeline([(\"Word2Vec Vectorizer\", W2vVectorizer(glove)),\n",
    "              ('Logistic Regression', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Random Forest', rf)]\n",
    "#           (\"Support Vector Machine\", svc),\n",
    "#           (\"Logistic Regression\", lr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "scores = [(name, cross_val_score(model, data, target, cv=2).mean()) for name, model, in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Random Forest', 0.7324304483223025)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning w/ Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(list(df.text))\n",
    "list_tokenized_tweets = tokenizer.texts_to_sequences(df.text)\n",
    "X_t = sequence.pad_sequences(list_tokenized_tweets, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(target).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "input_ = Input(shape=(20,))\n",
    "x = Embedding(5000, embedding_size)(input_)\n",
    "x = LSTM(100, return_sequences=True)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(50, kernel_regularizer=regularizers.l2(0.5))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(25)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(25)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(50, kernel_regularizer=regularizers.l2(0.5))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# There are 2 different possible classes, so we use 2 neurons in our output layer\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.00005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_45 (Embedding)     (None, 20, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 20, 100)           53200     \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 20, 50)            5050      \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 20, 25)            1275      \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 20, 25)            650       \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_45 (Glo (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 221,526\n",
      "Trainable params: 221,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reuben/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6090 samples, validate on 1523 samples\n",
      "Epoch 1/400\n",
      "6090/6090 [==============================] - 5s 816us/step - loss: 49.9562 - accuracy: 0.5177 - val_loss: 48.9281 - val_accuracy: 0.5345\n",
      "Epoch 2/400\n",
      "6090/6090 [==============================] - 4s 655us/step - loss: 47.9551 - accuracy: 0.5560 - val_loss: 46.9724 - val_accuracy: 0.5345\n",
      "Epoch 3/400\n",
      "6090/6090 [==============================] - 4s 692us/step - loss: 46.0357 - accuracy: 0.5622 - val_loss: 45.0913 - val_accuracy: 0.5345\n",
      "Epoch 4/400\n",
      "6090/6090 [==============================] - 4s 679us/step - loss: 44.1896 - accuracy: 0.5637 - val_loss: 43.2850 - val_accuracy: 0.5345\n",
      "Epoch 5/400\n",
      "6090/6090 [==============================] - 4s 653us/step - loss: 42.4177 - accuracy: 0.5759 - val_loss: 41.5493 - val_accuracy: 0.5345\n",
      "Epoch 6/400\n",
      "6090/6090 [==============================] - 4s 670us/step - loss: 40.7156 - accuracy: 0.5752 - val_loss: 39.8809 - val_accuracy: 0.5345\n",
      "Epoch 7/400\n",
      "6090/6090 [==============================] - 4s 662us/step - loss: 39.0787 - accuracy: 0.5693 - val_loss: 38.2764 - val_accuracy: 0.5345\n",
      "Epoch 8/400\n",
      "6090/6090 [==============================] - 4s 664us/step - loss: 37.5042 - accuracy: 0.5727 - val_loss: 36.7329 - val_accuracy: 0.5345\n",
      "Epoch 9/400\n",
      "6090/6090 [==============================] - 4s 671us/step - loss: 35.9876 - accuracy: 0.5724 - val_loss: 35.2479 - val_accuracy: 0.5345\n",
      "Epoch 10/400\n",
      "6090/6090 [==============================] - 4s 675us/step - loss: 34.5301 - accuracy: 0.5775 - val_loss: 33.8186 - val_accuracy: 0.5345\n",
      "Epoch 11/400\n",
      "6090/6090 [==============================] - 4s 668us/step - loss: 33.1274 - accuracy: 0.5749 - val_loss: 32.4428 - val_accuracy: 0.5345\n",
      "Epoch 12/400\n",
      "6090/6090 [==============================] - 4s 671us/step - loss: 31.7766 - accuracy: 0.5724 - val_loss: 31.1185 - val_accuracy: 0.5345\n",
      "Epoch 13/400\n",
      "6090/6090 [==============================] - 4s 676us/step - loss: 30.4769 - accuracy: 0.5760 - val_loss: 29.8436 - val_accuracy: 0.5345\n",
      "Epoch 14/400\n",
      "6090/6090 [==============================] - 4s 680us/step - loss: 29.2268 - accuracy: 0.5741 - val_loss: 28.6163 - val_accuracy: 0.5345\n",
      "Epoch 15/400\n",
      "6090/6090 [==============================] - 4s 682us/step - loss: 28.0195 - accuracy: 0.5755 - val_loss: 27.4345 - val_accuracy: 0.5345\n",
      "Epoch 16/400\n",
      "6090/6090 [==============================] - 4s 677us/step - loss: 26.8575 - accuracy: 0.5749 - val_loss: 26.2966 - val_accuracy: 0.5345\n",
      "Epoch 17/400\n",
      "6090/6090 [==============================] - 4s 678us/step - loss: 25.7390 - accuracy: 0.5752 - val_loss: 25.2008 - val_accuracy: 0.5345\n",
      "Epoch 18/400\n",
      "6090/6090 [==============================] - 4s 684us/step - loss: 24.6620 - accuracy: 0.5731 - val_loss: 24.1455 - val_accuracy: 0.5345\n",
      "Epoch 19/400\n",
      "6090/6090 [==============================] - 4s 677us/step - loss: 23.6237 - accuracy: 0.5752 - val_loss: 23.1276 - val_accuracy: 0.5345\n",
      "Epoch 20/400\n",
      "6090/6090 [==============================] - 4s 688us/step - loss: 22.6211 - accuracy: 0.5744 - val_loss: 22.1485 - val_accuracy: 0.5345\n",
      "Epoch 21/400\n",
      "6090/6090 [==============================] - 4s 676us/step - loss: 21.6442 - accuracy: 0.5962 - val_loss: 21.1944 - val_accuracy: 0.5371\n",
      "Epoch 22/400\n",
      "6090/6090 [==============================] - 4s 684us/step - loss: 20.7038 - accuracy: 0.6286 - val_loss: 20.2811 - val_accuracy: 0.6507\n",
      "Epoch 23/400\n",
      "6090/6090 [==============================] - 4s 674us/step - loss: 19.7956 - accuracy: 0.6672 - val_loss: 19.4059 - val_accuracy: 0.7091\n",
      "Epoch 24/400\n",
      "6090/6090 [==============================] - 4s 682us/step - loss: 18.9268 - accuracy: 0.6939 - val_loss: 18.5537 - val_accuracy: 0.7045\n",
      "Epoch 25/400\n",
      "6090/6090 [==============================] - 4s 683us/step - loss: 18.0845 - accuracy: 0.7166 - val_loss: 17.7425 - val_accuracy: 0.7269\n",
      "Epoch 26/400\n",
      "6090/6090 [==============================] - 4s 686us/step - loss: 17.2701 - accuracy: 0.7369 - val_loss: 16.9642 - val_accuracy: 0.7439\n",
      "Epoch 27/400\n",
      "6090/6090 [==============================] - 4s 681us/step - loss: 16.4989 - accuracy: 0.7567 - val_loss: 16.2096 - val_accuracy: 0.7466\n",
      "Epoch 28/400\n",
      "6090/6090 [==============================] - 4s 685us/step - loss: 15.7560 - accuracy: 0.7696 - val_loss: 15.4862 - val_accuracy: 0.7492\n",
      "Epoch 29/400\n",
      "6090/6090 [==============================] - 4s 677us/step - loss: 15.0371 - accuracy: 0.7851 - val_loss: 14.7917 - val_accuracy: 0.7433\n",
      "Epoch 30/400\n",
      "6090/6090 [==============================] - 4s 685us/step - loss: 14.3505 - accuracy: 0.8033 - val_loss: 14.1343 - val_accuracy: 0.7485\n",
      "Epoch 31/400\n",
      "6090/6090 [==============================] - 4s 685us/step - loss: 13.6902 - accuracy: 0.8080 - val_loss: 13.4884 - val_accuracy: 0.7459\n",
      "Epoch 32/400\n",
      "6090/6090 [==============================] - 4s 697us/step - loss: 13.0585 - accuracy: 0.8166 - val_loss: 12.8787 - val_accuracy: 0.7426\n",
      "Epoch 33/400\n",
      "6090/6090 [==============================] - 4s 691us/step - loss: 12.4493 - accuracy: 0.8225 - val_loss: 12.2989 - val_accuracy: 0.7492\n",
      "Epoch 34/400\n",
      "6090/6090 [==============================] - 4s 681us/step - loss: 11.8661 - accuracy: 0.8287 - val_loss: 11.7275 - val_accuracy: 0.7472\n",
      "Epoch 35/400\n",
      "6090/6090 [==============================] - 4s 688us/step - loss: 11.3063 - accuracy: 0.8323 - val_loss: 11.1821 - val_accuracy: 0.7466\n",
      "Epoch 36/400\n",
      "6090/6090 [==============================] - 4s 681us/step - loss: 10.7688 - accuracy: 0.8414 - val_loss: 10.6716 - val_accuracy: 0.7472\n",
      "Epoch 37/400\n",
      "6090/6090 [==============================] - 4s 684us/step - loss: 10.2468 - accuracy: 0.8479 - val_loss: 10.1805 - val_accuracy: 0.7505\n",
      "Epoch 38/400\n",
      "6090/6090 [==============================] - 4s 690us/step - loss: 9.7508 - accuracy: 0.8470 - val_loss: 9.7063 - val_accuracy: 0.7511\n",
      "Epoch 39/400\n",
      "6090/6090 [==============================] - 4s 687us/step - loss: 9.2849 - accuracy: 0.8537 - val_loss: 9.2500 - val_accuracy: 0.7525\n",
      "Epoch 40/400\n",
      "6090/6090 [==============================] - 4s 692us/step - loss: 8.8269 - accuracy: 0.8565 - val_loss: 8.8135 - val_accuracy: 0.7564\n",
      "Epoch 41/400\n",
      "6090/6090 [==============================] - 4s 686us/step - loss: 8.3894 - accuracy: 0.8663 - val_loss: 8.4006 - val_accuracy: 0.7564\n",
      "Epoch 42/400\n",
      "6090/6090 [==============================] - 4s 689us/step - loss: 7.9690 - accuracy: 0.8662 - val_loss: 8.0021 - val_accuracy: 0.7571\n",
      "Epoch 43/400\n",
      "6090/6090 [==============================] - 4s 687us/step - loss: 7.5767 - accuracy: 0.8650 - val_loss: 7.6115 - val_accuracy: 0.7485\n",
      "Epoch 44/400\n",
      "6090/6090 [==============================] - 4s 692us/step - loss: 7.1955 - accuracy: 0.8736 - val_loss: 7.2503 - val_accuracy: 0.7472\n",
      "Epoch 45/400\n",
      "6090/6090 [==============================] - 4s 689us/step - loss: 6.8286 - accuracy: 0.8759 - val_loss: 6.9039 - val_accuracy: 0.7485\n",
      "Epoch 46/400\n",
      "6090/6090 [==============================] - 4s 689us/step - loss: 6.4801 - accuracy: 0.8744 - val_loss: 6.5704 - val_accuracy: 0.7466\n",
      "Epoch 47/400\n",
      "6090/6090 [==============================] - 4s 682us/step - loss: 6.1549 - accuracy: 0.8795 - val_loss: 6.2503 - val_accuracy: 0.7459\n",
      "Epoch 48/400\n",
      "6090/6090 [==============================] - 4s 689us/step - loss: 5.8244 - accuracy: 0.8851 - val_loss: 5.9555 - val_accuracy: 0.7426\n",
      "Epoch 49/400\n",
      "6090/6090 [==============================] - 4s 714us/step - loss: 5.5249 - accuracy: 0.8844 - val_loss: 5.6556 - val_accuracy: 0.7446\n",
      "Epoch 50/400\n",
      "6090/6090 [==============================] - 5s 812us/step - loss: 5.2340 - accuracy: 0.8905 - val_loss: 5.3848 - val_accuracy: 0.7413\n",
      "Epoch 51/400\n",
      "6090/6090 [==============================] - 5s 824us/step - loss: 4.9585 - accuracy: 0.8888 - val_loss: 5.1115 - val_accuracy: 0.7374\n",
      "Epoch 52/400\n",
      "6090/6090 [==============================] - 5s 855us/step - loss: 4.6908 - accuracy: 0.8913 - val_loss: 4.8653 - val_accuracy: 0.7420\n",
      "Epoch 53/400\n",
      "6090/6090 [==============================] - 5s 877us/step - loss: 4.4425 - accuracy: 0.8913 - val_loss: 4.6315 - val_accuracy: 0.7439\n",
      "Epoch 54/400\n",
      "6090/6090 [==============================] - 4s 622us/step - loss: 4.2041 - accuracy: 0.8939 - val_loss: 4.4016 - val_accuracy: 0.7374\n",
      "Epoch 55/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090/6090 [==============================] - 4s 584us/step - loss: 3.9762 - accuracy: 0.8911 - val_loss: 4.1851 - val_accuracy: 0.7393\n",
      "Epoch 56/400\n",
      "6090/6090 [==============================] - 3s 571us/step - loss: 3.7606 - accuracy: 0.8952 - val_loss: 3.9755 - val_accuracy: 0.7380\n",
      "Epoch 57/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 3.5521 - accuracy: 0.8982 - val_loss: 3.7915 - val_accuracy: 0.7406\n",
      "Epoch 58/400\n",
      "6090/6090 [==============================] - 3s 574us/step - loss: 3.3659 - accuracy: 0.8908 - val_loss: 3.6023 - val_accuracy: 0.7341\n",
      "Epoch 59/400\n",
      "6090/6090 [==============================] - 4s 577us/step - loss: 3.1733 - accuracy: 0.9007 - val_loss: 3.4216 - val_accuracy: 0.7380\n",
      "Epoch 60/400\n",
      "6090/6090 [==============================] - 3s 574us/step - loss: 2.9925 - accuracy: 0.9036 - val_loss: 3.2660 - val_accuracy: 0.7393\n",
      "Epoch 61/400\n",
      "6090/6090 [==============================] - 4s 592us/step - loss: 2.8266 - accuracy: 0.9049 - val_loss: 3.1030 - val_accuracy: 0.7426\n",
      "Epoch 62/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 2.6687 - accuracy: 0.9041 - val_loss: 2.9649 - val_accuracy: 0.7334\n",
      "Epoch 63/400\n",
      "6090/6090 [==============================] - 4s 598us/step - loss: 2.5145 - accuracy: 0.9067 - val_loss: 2.8276 - val_accuracy: 0.7203\n",
      "Epoch 64/400\n",
      "6090/6090 [==============================] - 4s 596us/step - loss: 2.3847 - accuracy: 0.9069 - val_loss: 2.6719 - val_accuracy: 0.7321\n",
      "Epoch 65/400\n",
      "6090/6090 [==============================] - 4s 593us/step - loss: 2.2372 - accuracy: 0.9082 - val_loss: 2.5504 - val_accuracy: 0.7413\n",
      "Epoch 66/400\n",
      "6090/6090 [==============================] - 4s 591us/step - loss: 2.1103 - accuracy: 0.9092 - val_loss: 2.4369 - val_accuracy: 0.7387\n",
      "Epoch 67/400\n",
      "6090/6090 [==============================] - 4s 597us/step - loss: 1.9920 - accuracy: 0.9115 - val_loss: 2.3239 - val_accuracy: 0.7380\n",
      "Epoch 68/400\n",
      "6090/6090 [==============================] - 4s 629us/step - loss: 1.8841 - accuracy: 0.9071 - val_loss: 2.2117 - val_accuracy: 0.7295\n",
      "Epoch 69/400\n",
      "6090/6090 [==============================] - 4s 613us/step - loss: 1.7713 - accuracy: 0.9122 - val_loss: 2.1129 - val_accuracy: 0.7354\n",
      "Epoch 70/400\n",
      "6090/6090 [==============================] - 6s 999us/step - loss: 1.6708 - accuracy: 0.9130 - val_loss: 2.0225 - val_accuracy: 0.7308\n",
      "Epoch 71/400\n",
      "6090/6090 [==============================] - 4s 649us/step - loss: 1.5768 - accuracy: 0.9122 - val_loss: 1.9298 - val_accuracy: 0.7347\n",
      "Epoch 72/400\n",
      "6090/6090 [==============================] - 3s 568us/step - loss: 1.4893 - accuracy: 0.9130 - val_loss: 1.8511 - val_accuracy: 0.7295\n",
      "Epoch 73/400\n",
      "6090/6090 [==============================] - 3s 568us/step - loss: 1.3931 - accuracy: 0.9159 - val_loss: 1.7785 - val_accuracy: 0.7269\n",
      "Epoch 74/400\n",
      "6090/6090 [==============================] - 3s 572us/step - loss: 1.3149 - accuracy: 0.9179 - val_loss: 1.7063 - val_accuracy: 0.7334\n",
      "Epoch 75/400\n",
      "6090/6090 [==============================] - 4s 611us/step - loss: 1.2425 - accuracy: 0.9151 - val_loss: 1.6363 - val_accuracy: 0.7301\n",
      "Epoch 76/400\n",
      "6090/6090 [==============================] - 4s 617us/step - loss: 1.1698 - accuracy: 0.9179 - val_loss: 1.5604 - val_accuracy: 0.7328\n",
      "Epoch 77/400\n",
      "6090/6090 [==============================] - 4s 626us/step - loss: 1.1024 - accuracy: 0.9192 - val_loss: 1.5252 - val_accuracy: 0.7091\n",
      "Epoch 78/400\n",
      "6090/6090 [==============================] - 4s 605us/step - loss: 1.0542 - accuracy: 0.9140 - val_loss: 1.4334 - val_accuracy: 0.7209\n",
      "Epoch 79/400\n",
      "6090/6090 [==============================] - 4s 594us/step - loss: 0.9873 - accuracy: 0.9189 - val_loss: 1.3863 - val_accuracy: 0.7262\n",
      "Epoch 80/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.9285 - accuracy: 0.9166 - val_loss: 1.3512 - val_accuracy: 0.7131\n",
      "Epoch 81/400\n",
      "6090/6090 [==============================] - 4s 634us/step - loss: 0.8755 - accuracy: 0.9238 - val_loss: 1.3020 - val_accuracy: 0.7282\n",
      "Epoch 82/400\n",
      "6090/6090 [==============================] - 4s 600us/step - loss: 0.8249 - accuracy: 0.9256 - val_loss: 1.2684 - val_accuracy: 0.7282\n",
      "Epoch 83/400\n",
      "6090/6090 [==============================] - 4s 716us/step - loss: 0.7908 - accuracy: 0.9240 - val_loss: 1.2170 - val_accuracy: 0.7262\n",
      "Epoch 84/400\n",
      "6090/6090 [==============================] - 4s 727us/step - loss: 0.7449 - accuracy: 0.9199 - val_loss: 1.1814 - val_accuracy: 0.7275\n",
      "Epoch 85/400\n",
      "6090/6090 [==============================] - 3s 564us/step - loss: 0.6985 - accuracy: 0.9269 - val_loss: 1.1539 - val_accuracy: 0.7163\n",
      "Epoch 86/400\n",
      "6090/6090 [==============================] - 4s 577us/step - loss: 0.6678 - accuracy: 0.9256 - val_loss: 1.1228 - val_accuracy: 0.7190\n",
      "Epoch 87/400\n",
      "6090/6090 [==============================] - 3s 569us/step - loss: 0.6287 - accuracy: 0.9248 - val_loss: 1.0780 - val_accuracy: 0.7269\n",
      "Epoch 88/400\n",
      "6090/6090 [==============================] - 3s 557us/step - loss: 0.5992 - accuracy: 0.9240 - val_loss: 1.0321 - val_accuracy: 0.7295\n",
      "Epoch 89/400\n",
      "6090/6090 [==============================] - 3s 574us/step - loss: 0.5717 - accuracy: 0.9307 - val_loss: 1.0273 - val_accuracy: 0.7249\n",
      "Epoch 90/400\n",
      "6090/6090 [==============================] - 3s 569us/step - loss: 0.5374 - accuracy: 0.9291 - val_loss: 0.9987 - val_accuracy: 0.7262\n",
      "Epoch 91/400\n",
      "6090/6090 [==============================] - 3s 564us/step - loss: 0.5134 - accuracy: 0.9276 - val_loss: 0.9808 - val_accuracy: 0.7209\n",
      "Epoch 92/400\n",
      "6090/6090 [==============================] - 4s 577us/step - loss: 0.4877 - accuracy: 0.9274 - val_loss: 0.9846 - val_accuracy: 0.6934\n",
      "Epoch 93/400\n",
      "6090/6090 [==============================] - 4s 609us/step - loss: 0.4710 - accuracy: 0.9278 - val_loss: 0.9266 - val_accuracy: 0.7223\n",
      "Epoch 94/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.4438 - accuracy: 0.9302 - val_loss: 0.9092 - val_accuracy: 0.7255\n",
      "Epoch 95/400\n",
      "6090/6090 [==============================] - 3s 574us/step - loss: 0.4290 - accuracy: 0.9278 - val_loss: 0.8860 - val_accuracy: 0.7255\n",
      "Epoch 96/400\n",
      "6090/6090 [==============================] - 4s 601us/step - loss: 0.4137 - accuracy: 0.9287 - val_loss: 0.8645 - val_accuracy: 0.7269\n",
      "Epoch 97/400\n",
      "6090/6090 [==============================] - 4s 628us/step - loss: 0.3970 - accuracy: 0.9325 - val_loss: 0.8759 - val_accuracy: 0.7085\n",
      "Epoch 98/400\n",
      "6090/6090 [==============================] - 4s 642us/step - loss: 0.3724 - accuracy: 0.9338 - val_loss: 0.8571 - val_accuracy: 0.7223\n",
      "Epoch 99/400\n",
      "6090/6090 [==============================] - 5s 758us/step - loss: 0.3631 - accuracy: 0.9333 - val_loss: 0.8368 - val_accuracy: 0.7288\n",
      "Epoch 100/400\n",
      "6090/6090 [==============================] - 4s 637us/step - loss: 0.3421 - accuracy: 0.9365 - val_loss: 0.8522 - val_accuracy: 0.7183\n",
      "Epoch 101/400\n",
      "6090/6090 [==============================] - 4s 637us/step - loss: 0.3354 - accuracy: 0.9338 - val_loss: 0.8352 - val_accuracy: 0.7144\n",
      "Epoch 102/400\n",
      "6090/6090 [==============================] - 5s 798us/step - loss: 0.3230 - accuracy: 0.9397 - val_loss: 0.8130 - val_accuracy: 0.7295\n",
      "Epoch 103/400\n",
      "6090/6090 [==============================] - 4s 645us/step - loss: 0.3144 - accuracy: 0.9346 - val_loss: 0.8126 - val_accuracy: 0.7118\n",
      "Epoch 104/400\n",
      "6090/6090 [==============================] - 4s 700us/step - loss: 0.3056 - accuracy: 0.9374 - val_loss: 0.7972 - val_accuracy: 0.7177\n",
      "Epoch 105/400\n",
      "6090/6090 [==============================] - 4s 713us/step - loss: 0.2914 - accuracy: 0.9417 - val_loss: 0.7957 - val_accuracy: 0.7255\n",
      "Epoch 106/400\n",
      "6090/6090 [==============================] - 4s 709us/step - loss: 0.2884 - accuracy: 0.9360 - val_loss: 0.7861 - val_accuracy: 0.7223\n",
      "Epoch 107/400\n",
      "6090/6090 [==============================] - 4s 667us/step - loss: 0.2736 - accuracy: 0.9407 - val_loss: 0.7959 - val_accuracy: 0.7203\n",
      "Epoch 108/400\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.2668 - accuracy: 0.9402 - val_loss: 0.7761 - val_accuracy: 0.7255\n",
      "Epoch 109/400\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.2626 - accuracy: 0.9392 - val_loss: 0.7838 - val_accuracy: 0.7131\n",
      "Epoch 110/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090/6090 [==============================] - 4s 702us/step - loss: 0.2510 - accuracy: 0.9401 - val_loss: 0.7833 - val_accuracy: 0.7157\n",
      "Epoch 111/400\n",
      "6090/6090 [==============================] - 4s 698us/step - loss: 0.2548 - accuracy: 0.9379 - val_loss: 0.7516 - val_accuracy: 0.7118\n",
      "Epoch 112/400\n",
      "6090/6090 [==============================] - 4s 661us/step - loss: 0.2456 - accuracy: 0.9420 - val_loss: 0.7590 - val_accuracy: 0.7124\n",
      "Epoch 113/400\n",
      "6090/6090 [==============================] - 4s 614us/step - loss: 0.2416 - accuracy: 0.9406 - val_loss: 0.7612 - val_accuracy: 0.7118\n",
      "Epoch 114/400\n",
      "6090/6090 [==============================] - 4s 612us/step - loss: 0.2362 - accuracy: 0.9397 - val_loss: 0.7631 - val_accuracy: 0.7111\n",
      "Epoch 115/400\n",
      "6090/6090 [==============================] - 5s 787us/step - loss: 0.2255 - accuracy: 0.9440 - val_loss: 0.7592 - val_accuracy: 0.7242\n",
      "Epoch 116/400\n",
      "6090/6090 [==============================] - 4s 684us/step - loss: 0.2233 - accuracy: 0.9432 - val_loss: 0.7579 - val_accuracy: 0.7163\n",
      "Epoch 117/400\n",
      "6090/6090 [==============================] - 5s 891us/step - loss: 0.2214 - accuracy: 0.9406 - val_loss: 0.7849 - val_accuracy: 0.6875\n",
      "Epoch 118/400\n",
      "6090/6090 [==============================] - 4s 665us/step - loss: 0.2153 - accuracy: 0.9422 - val_loss: 0.7648 - val_accuracy: 0.7150\n",
      "Epoch 119/400\n",
      "6090/6090 [==============================] - 4s 656us/step - loss: 0.2130 - accuracy: 0.9420 - val_loss: 0.7455 - val_accuracy: 0.7183\n",
      "Epoch 120/400\n",
      "6090/6090 [==============================] - 4s 729us/step - loss: 0.2083 - accuracy: 0.9445 - val_loss: 0.7663 - val_accuracy: 0.7131\n",
      "Epoch 121/400\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.2075 - accuracy: 0.9402 - val_loss: 0.7491 - val_accuracy: 0.7216\n",
      "Epoch 122/400\n",
      "6090/6090 [==============================] - 4s 700us/step - loss: 0.2058 - accuracy: 0.9425 - val_loss: 0.7576 - val_accuracy: 0.7137\n",
      "Epoch 123/400\n",
      "6090/6090 [==============================] - 5s 767us/step - loss: 0.2028 - accuracy: 0.9432 - val_loss: 0.7756 - val_accuracy: 0.7144\n",
      "Epoch 124/400\n",
      "6090/6090 [==============================] - 4s 673us/step - loss: 0.2020 - accuracy: 0.9435 - val_loss: 0.7727 - val_accuracy: 0.7170\n",
      "Epoch 125/400\n",
      "6090/6090 [==============================] - 4s 618us/step - loss: 0.1957 - accuracy: 0.9460 - val_loss: 0.7674 - val_accuracy: 0.7131\n",
      "Epoch 126/400\n",
      "6090/6090 [==============================] - 4s 606us/step - loss: 0.1954 - accuracy: 0.9433 - val_loss: 0.7898 - val_accuracy: 0.7032\n",
      "Epoch 127/400\n",
      "6090/6090 [==============================] - 4s 641us/step - loss: 0.2017 - accuracy: 0.9411 - val_loss: 0.7522 - val_accuracy: 0.7229\n",
      "Epoch 128/400\n",
      "6090/6090 [==============================] - 4s 667us/step - loss: 0.1933 - accuracy: 0.9455 - val_loss: 0.7704 - val_accuracy: 0.7157\n",
      "Epoch 129/400\n",
      "6090/6090 [==============================] - 4s 708us/step - loss: 0.1947 - accuracy: 0.9437 - val_loss: 0.7480 - val_accuracy: 0.7282\n",
      "Epoch 130/400\n",
      "6090/6090 [==============================] - 4s 687us/step - loss: 0.1929 - accuracy: 0.9447 - val_loss: 0.7698 - val_accuracy: 0.7229\n",
      "Epoch 131/400\n",
      "6090/6090 [==============================] - 4s 704us/step - loss: 0.1890 - accuracy: 0.9465 - val_loss: 0.7853 - val_accuracy: 0.7170\n",
      "Epoch 132/400\n",
      "6090/6090 [==============================] - 4s 630us/step - loss: 0.1847 - accuracy: 0.9468 - val_loss: 0.7754 - val_accuracy: 0.7170\n",
      "Epoch 133/400\n",
      "6090/6090 [==============================] - 4s 674us/step - loss: 0.1874 - accuracy: 0.9452 - val_loss: 0.7455 - val_accuracy: 0.7203\n",
      "Epoch 134/400\n",
      "6090/6090 [==============================] - 6s 931us/step - loss: 0.1788 - accuracy: 0.9473 - val_loss: 0.7863 - val_accuracy: 0.7144\n",
      "Epoch 135/400\n",
      "6090/6090 [==============================] - 5s 759us/step - loss: 0.1815 - accuracy: 0.9468 - val_loss: 0.7700 - val_accuracy: 0.7196\n",
      "Epoch 136/400\n",
      "6090/6090 [==============================] - 4s 729us/step - loss: 0.1727 - accuracy: 0.9504 - val_loss: 0.7909 - val_accuracy: 0.7163\n",
      "Epoch 137/400\n",
      "6090/6090 [==============================] - 5s 762us/step - loss: 0.1760 - accuracy: 0.9512 - val_loss: 0.7898 - val_accuracy: 0.7223\n",
      "Epoch 138/400\n",
      "6090/6090 [==============================] - 9s 1ms/step - loss: 0.1770 - accuracy: 0.9514 - val_loss: 0.7748 - val_accuracy: 0.7190\n",
      "Epoch 139/400\n",
      "6090/6090 [==============================] - 5s 896us/step - loss: 0.1723 - accuracy: 0.9512 - val_loss: 0.7769 - val_accuracy: 0.7196\n",
      "Epoch 140/400\n",
      "6090/6090 [==============================] - 5s 902us/step - loss: 0.1743 - accuracy: 0.9529 - val_loss: 0.7982 - val_accuracy: 0.7163\n",
      "Epoch 141/400\n",
      "6090/6090 [==============================] - 4s 687us/step - loss: 0.1778 - accuracy: 0.9461 - val_loss: 0.7600 - val_accuracy: 0.7170\n",
      "Epoch 142/400\n",
      "6090/6090 [==============================] - 4s 673us/step - loss: 0.1720 - accuracy: 0.9475 - val_loss: 0.8004 - val_accuracy: 0.7177\n",
      "Epoch 143/400\n",
      "6090/6090 [==============================] - 5s 874us/step - loss: 0.1738 - accuracy: 0.9516 - val_loss: 0.7748 - val_accuracy: 0.7170\n",
      "Epoch 144/400\n",
      "6090/6090 [==============================] - 5s 760us/step - loss: 0.1721 - accuracy: 0.9514 - val_loss: 0.7885 - val_accuracy: 0.7091\n",
      "Epoch 145/400\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.1719 - accuracy: 0.9506 - val_loss: 0.7828 - val_accuracy: 0.7111\n",
      "Epoch 146/400\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.1717 - accuracy: 0.9496 - val_loss: 0.7979 - val_accuracy: 0.7170\n",
      "Epoch 147/400\n",
      "6090/6090 [==============================] - 4s 696us/step - loss: 0.1681 - accuracy: 0.9529 - val_loss: 0.7966 - val_accuracy: 0.7177\n",
      "Epoch 148/400\n",
      "6090/6090 [==============================] - 4s 636us/step - loss: 0.1693 - accuracy: 0.9516 - val_loss: 0.8523 - val_accuracy: 0.7006\n",
      "Epoch 149/400\n",
      "6090/6090 [==============================] - 4s 720us/step - loss: 0.1635 - accuracy: 0.9524 - val_loss: 0.8282 - val_accuracy: 0.7144\n",
      "Epoch 150/400\n",
      "6090/6090 [==============================] - 5s 749us/step - loss: 0.1644 - accuracy: 0.9522 - val_loss: 0.8212 - val_accuracy: 0.7150\n",
      "Epoch 151/400\n",
      "6090/6090 [==============================] - 4s 648us/step - loss: 0.1608 - accuracy: 0.9537 - val_loss: 0.8370 - val_accuracy: 0.7137\n",
      "Epoch 152/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1663 - accuracy: 0.9530 - val_loss: 0.8049 - val_accuracy: 0.7190\n",
      "Epoch 153/400\n",
      "6090/6090 [==============================] - 4s 647us/step - loss: 0.1711 - accuracy: 0.9481 - val_loss: 0.7661 - val_accuracy: 0.7282\n",
      "Epoch 154/400\n",
      "6090/6090 [==============================] - 4s 619us/step - loss: 0.1641 - accuracy: 0.9512 - val_loss: 0.8061 - val_accuracy: 0.7236\n",
      "Epoch 155/400\n",
      "6090/6090 [==============================] - 4s 592us/step - loss: 0.1592 - accuracy: 0.9514 - val_loss: 0.8473 - val_accuracy: 0.7157\n",
      "Epoch 156/400\n",
      "6090/6090 [==============================] - 3s 574us/step - loss: 0.1636 - accuracy: 0.9506 - val_loss: 0.8176 - val_accuracy: 0.7131\n",
      "Epoch 157/400\n",
      "6090/6090 [==============================] - 4s 618us/step - loss: 0.1660 - accuracy: 0.9496 - val_loss: 0.8328 - val_accuracy: 0.7157\n",
      "Epoch 158/400\n",
      "6090/6090 [==============================] - 4s 627us/step - loss: 0.1608 - accuracy: 0.9555 - val_loss: 0.8316 - val_accuracy: 0.7137\n",
      "Epoch 159/400\n",
      "6090/6090 [==============================] - 5s 758us/step - loss: 0.1575 - accuracy: 0.9562 - val_loss: 0.8670 - val_accuracy: 0.7124\n",
      "Epoch 160/400\n",
      "6090/6090 [==============================] - 4s 688us/step - loss: 0.1597 - accuracy: 0.9522 - val_loss: 0.8292 - val_accuracy: 0.7065\n",
      "Epoch 161/400\n",
      "6090/6090 [==============================] - 6s 1ms/step - loss: 0.1540 - accuracy: 0.9547 - val_loss: 0.8627 - val_accuracy: 0.7137\n",
      "Epoch 162/400\n",
      "6090/6090 [==============================] - 5s 804us/step - loss: 0.1599 - accuracy: 0.9532 - val_loss: 0.8324 - val_accuracy: 0.6999\n",
      "Epoch 163/400\n",
      "6090/6090 [==============================] - 6s 975us/step - loss: 0.1585 - accuracy: 0.9516 - val_loss: 0.8053 - val_accuracy: 0.7229\n",
      "Epoch 164/400\n",
      "6090/6090 [==============================] - 7s 1ms/step - loss: 0.1564 - accuracy: 0.9530 - val_loss: 0.8620 - val_accuracy: 0.7098\n",
      "Epoch 165/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090/6090 [==============================] - 4s 732us/step - loss: 0.1559 - accuracy: 0.9521 - val_loss: 0.8566 - val_accuracy: 0.7111\n",
      "Epoch 166/400\n",
      "6090/6090 [==============================] - 4s 687us/step - loss: 0.1502 - accuracy: 0.9560 - val_loss: 0.8558 - val_accuracy: 0.7118\n",
      "Epoch 167/400\n",
      "6090/6090 [==============================] - 5s 758us/step - loss: 0.1495 - accuracy: 0.9530 - val_loss: 0.8728 - val_accuracy: 0.7039\n",
      "Epoch 168/400\n",
      "6090/6090 [==============================] - 5s 740us/step - loss: 0.1544 - accuracy: 0.9534 - val_loss: 0.8440 - val_accuracy: 0.7072\n",
      "Epoch 169/400\n",
      "6090/6090 [==============================] - 4s 675us/step - loss: 0.1529 - accuracy: 0.9567 - val_loss: 0.8799 - val_accuracy: 0.6947\n",
      "Epoch 170/400\n",
      "6090/6090 [==============================] - 6s 964us/step - loss: 0.1582 - accuracy: 0.9534 - val_loss: 0.8390 - val_accuracy: 0.7104\n",
      "Epoch 171/400\n",
      "6090/6090 [==============================] - 5s 875us/step - loss: 0.1527 - accuracy: 0.9539 - val_loss: 0.8510 - val_accuracy: 0.7111\n",
      "Epoch 172/400\n",
      "6090/6090 [==============================] - 6s 928us/step - loss: 0.1473 - accuracy: 0.9548 - val_loss: 0.8747 - val_accuracy: 0.7118\n",
      "Epoch 173/400\n",
      "6090/6090 [==============================] - 4s 713us/step - loss: 0.1456 - accuracy: 0.9530 - val_loss: 0.8597 - val_accuracy: 0.7039\n",
      "Epoch 174/400\n",
      "6090/6090 [==============================] - 4s 698us/step - loss: 0.1462 - accuracy: 0.9606 - val_loss: 0.9066 - val_accuracy: 0.7012\n",
      "Epoch 175/400\n",
      "6090/6090 [==============================] - 5s 766us/step - loss: 0.1546 - accuracy: 0.9535 - val_loss: 0.7908 - val_accuracy: 0.7216\n",
      "Epoch 176/400\n",
      "6090/6090 [==============================] - 5s 832us/step - loss: 0.1472 - accuracy: 0.9535 - val_loss: 0.8911 - val_accuracy: 0.7131\n",
      "Epoch 177/400\n",
      "6090/6090 [==============================] - 4s 674us/step - loss: 0.1462 - accuracy: 0.9563 - val_loss: 0.9024 - val_accuracy: 0.7137\n",
      "Epoch 178/400\n",
      "6090/6090 [==============================] - 4s 704us/step - loss: 0.1443 - accuracy: 0.9586 - val_loss: 0.9138 - val_accuracy: 0.7144\n",
      "Epoch 179/400\n",
      "6090/6090 [==============================] - 6s 979us/step - loss: 0.1403 - accuracy: 0.9580 - val_loss: 0.9802 - val_accuracy: 0.6835\n",
      "Epoch 180/400\n",
      "6090/6090 [==============================] - 5s 765us/step - loss: 0.1471 - accuracy: 0.9540 - val_loss: 0.9216 - val_accuracy: 0.7039\n",
      "Epoch 181/400\n",
      "6090/6090 [==============================] - 4s 639us/step - loss: 0.1380 - accuracy: 0.9580 - val_loss: 0.8894 - val_accuracy: 0.7137\n",
      "Epoch 182/400\n",
      "6090/6090 [==============================] - 4s 684us/step - loss: 0.1419 - accuracy: 0.9609 - val_loss: 0.8752 - val_accuracy: 0.7118\n",
      "Epoch 183/400\n",
      "6090/6090 [==============================] - 5s 752us/step - loss: 0.1373 - accuracy: 0.9575 - val_loss: 0.9244 - val_accuracy: 0.7170\n",
      "Epoch 184/400\n",
      "6090/6090 [==============================] - 6s 975us/step - loss: 0.1374 - accuracy: 0.9576 - val_loss: 0.8842 - val_accuracy: 0.7131\n",
      "Epoch 185/400\n",
      "6090/6090 [==============================] - 5s 746us/step - loss: 0.1391 - accuracy: 0.9594 - val_loss: 0.9300 - val_accuracy: 0.7032\n",
      "Epoch 186/400\n",
      "6090/6090 [==============================] - 4s 616us/step - loss: 0.1371 - accuracy: 0.9567 - val_loss: 0.9131 - val_accuracy: 0.7085\n",
      "Epoch 187/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1384 - accuracy: 0.9596 - val_loss: 0.8865 - val_accuracy: 0.7065\n",
      "Epoch 188/400\n",
      "6090/6090 [==============================] - 3s 574us/step - loss: 0.1336 - accuracy: 0.9599 - val_loss: 0.9400 - val_accuracy: 0.7124\n",
      "Epoch 189/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1380 - accuracy: 0.9583 - val_loss: 0.9499 - val_accuracy: 0.6980\n",
      "Epoch 190/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.1302 - accuracy: 0.9594 - val_loss: 0.9465 - val_accuracy: 0.7137\n",
      "Epoch 191/400\n",
      "6090/6090 [==============================] - 4s 575us/step - loss: 0.1359 - accuracy: 0.9565 - val_loss: 0.9058 - val_accuracy: 0.7196\n",
      "Epoch 192/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1357 - accuracy: 0.9578 - val_loss: 0.9082 - val_accuracy: 0.7177\n",
      "Epoch 193/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1300 - accuracy: 0.9594 - val_loss: 0.9611 - val_accuracy: 0.7177\n",
      "Epoch 194/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1369 - accuracy: 0.9580 - val_loss: 0.9359 - val_accuracy: 0.7137\n",
      "Epoch 195/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.1338 - accuracy: 0.9591 - val_loss: 0.9420 - val_accuracy: 0.7118\n",
      "Epoch 196/400\n",
      "6090/6090 [==============================] - 4s 576us/step - loss: 0.1344 - accuracy: 0.9591 - val_loss: 0.9130 - val_accuracy: 0.7131\n",
      "Epoch 197/400\n",
      "6090/6090 [==============================] - 4s 576us/step - loss: 0.1359 - accuracy: 0.9601 - val_loss: 0.8967 - val_accuracy: 0.7032\n",
      "Epoch 198/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1333 - accuracy: 0.9603 - val_loss: 0.9777 - val_accuracy: 0.6980\n",
      "Epoch 199/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.1316 - accuracy: 0.9599 - val_loss: 0.9937 - val_accuracy: 0.6986\n",
      "Epoch 200/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.1344 - accuracy: 0.9593 - val_loss: 0.9598 - val_accuracy: 0.7026\n",
      "Epoch 201/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.1325 - accuracy: 0.9596 - val_loss: 0.9499 - val_accuracy: 0.6986\n",
      "Epoch 202/400\n",
      "6090/6090 [==============================] - 4s 590us/step - loss: 0.1313 - accuracy: 0.9612 - val_loss: 0.9407 - val_accuracy: 0.7104\n",
      "Epoch 203/400\n",
      "6090/6090 [==============================] - 4s 575us/step - loss: 0.1294 - accuracy: 0.9606 - val_loss: 0.9409 - val_accuracy: 0.7012\n",
      "Epoch 204/400\n",
      "6090/6090 [==============================] - 3s 573us/step - loss: 0.1342 - accuracy: 0.9609 - val_loss: 0.9487 - val_accuracy: 0.7019\n",
      "Epoch 205/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.1260 - accuracy: 0.9598 - val_loss: 0.9687 - val_accuracy: 0.7012\n",
      "Epoch 206/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.1278 - accuracy: 0.9598 - val_loss: 0.9818 - val_accuracy: 0.7032\n",
      "Epoch 207/400\n",
      "6090/6090 [==============================] - 4s 577us/step - loss: 0.1276 - accuracy: 0.9606 - val_loss: 1.0087 - val_accuracy: 0.7006\n",
      "Epoch 208/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1274 - accuracy: 0.9593 - val_loss: 0.9642 - val_accuracy: 0.7052\n",
      "Epoch 209/400\n",
      "6090/6090 [==============================] - 4s 609us/step - loss: 0.1229 - accuracy: 0.9635 - val_loss: 0.9395 - val_accuracy: 0.7150\n",
      "Epoch 210/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1260 - accuracy: 0.9640 - val_loss: 0.9722 - val_accuracy: 0.7019\n",
      "Epoch 211/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.1245 - accuracy: 0.9593 - val_loss: 0.9361 - val_accuracy: 0.7144\n",
      "Epoch 212/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1331 - accuracy: 0.9563 - val_loss: 1.0056 - val_accuracy: 0.6835\n",
      "Epoch 213/400\n",
      "6090/6090 [==============================] - 4s 589us/step - loss: 0.1234 - accuracy: 0.9606 - val_loss: 1.0189 - val_accuracy: 0.7039\n",
      "Epoch 214/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1275 - accuracy: 0.9606 - val_loss: 1.0108 - val_accuracy: 0.6960\n",
      "Epoch 215/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1250 - accuracy: 0.9604 - val_loss: 1.0153 - val_accuracy: 0.6986\n",
      "Epoch 216/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1198 - accuracy: 0.9609 - val_loss: 1.0149 - val_accuracy: 0.6980\n",
      "Epoch 217/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1220 - accuracy: 0.9616 - val_loss: 0.9703 - val_accuracy: 0.7019\n",
      "Epoch 218/400\n",
      "6090/6090 [==============================] - 4s 577us/step - loss: 0.1220 - accuracy: 0.9619 - val_loss: 1.0039 - val_accuracy: 0.7078\n",
      "Epoch 219/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1221 - accuracy: 0.9624 - val_loss: 1.0027 - val_accuracy: 0.6960\n",
      "Epoch 220/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090/6090 [==============================] - 4s 603us/step - loss: 0.1227 - accuracy: 0.9604 - val_loss: 1.0086 - val_accuracy: 0.7052\n",
      "Epoch 221/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.1228 - accuracy: 0.9619 - val_loss: 0.9671 - val_accuracy: 0.7039\n",
      "Epoch 222/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1252 - accuracy: 0.9614 - val_loss: 0.9596 - val_accuracy: 0.7058\n",
      "Epoch 223/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1151 - accuracy: 0.9627 - val_loss: 1.0934 - val_accuracy: 0.6986\n",
      "Epoch 224/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.1245 - accuracy: 0.9603 - val_loss: 1.0183 - val_accuracy: 0.6980\n",
      "Epoch 225/400\n",
      "6090/6090 [==============================] - 4s 590us/step - loss: 0.1204 - accuracy: 0.9640 - val_loss: 1.0029 - val_accuracy: 0.6980\n",
      "Epoch 226/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.1253 - accuracy: 0.9604 - val_loss: 0.9934 - val_accuracy: 0.6986\n",
      "Epoch 227/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.1177 - accuracy: 0.9629 - val_loss: 1.0323 - val_accuracy: 0.7072\n",
      "Epoch 228/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.1201 - accuracy: 0.9624 - val_loss: 1.0228 - val_accuracy: 0.6986\n",
      "Epoch 229/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1129 - accuracy: 0.9650 - val_loss: 1.0491 - val_accuracy: 0.6999\n",
      "Epoch 230/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1159 - accuracy: 0.9640 - val_loss: 1.0095 - val_accuracy: 0.6973\n",
      "Epoch 231/400\n",
      "6090/6090 [==============================] - 4s 591us/step - loss: 0.1199 - accuracy: 0.9612 - val_loss: 1.0037 - val_accuracy: 0.7032\n",
      "Epoch 232/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1194 - accuracy: 0.9616 - val_loss: 1.0063 - val_accuracy: 0.6947\n",
      "Epoch 233/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1205 - accuracy: 0.9626 - val_loss: 0.9847 - val_accuracy: 0.7058\n",
      "Epoch 234/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.1174 - accuracy: 0.9635 - val_loss: 1.0519 - val_accuracy: 0.7019\n",
      "Epoch 235/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1104 - accuracy: 0.9637 - val_loss: 1.0438 - val_accuracy: 0.7045\n",
      "Epoch 236/400\n",
      "6090/6090 [==============================] - 4s 596us/step - loss: 0.1158 - accuracy: 0.9655 - val_loss: 1.0776 - val_accuracy: 0.6940\n",
      "Epoch 237/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1141 - accuracy: 0.9647 - val_loss: 1.0765 - val_accuracy: 0.7039\n",
      "Epoch 238/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1166 - accuracy: 0.9644 - val_loss: 0.9959 - val_accuracy: 0.6999\n",
      "Epoch 239/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.1144 - accuracy: 0.9637 - val_loss: 1.0952 - val_accuracy: 0.6967\n",
      "Epoch 240/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.1102 - accuracy: 0.9642 - val_loss: 1.0273 - val_accuracy: 0.7058\n",
      "Epoch 241/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.1102 - accuracy: 0.9658 - val_loss: 1.0253 - val_accuracy: 0.7118\n",
      "Epoch 242/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.1219 - accuracy: 0.9627 - val_loss: 0.9671 - val_accuracy: 0.7026\n",
      "Epoch 243/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1146 - accuracy: 0.9612 - val_loss: 1.0246 - val_accuracy: 0.6953\n",
      "Epoch 244/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1102 - accuracy: 0.9645 - val_loss: 1.0244 - val_accuracy: 0.6973\n",
      "Epoch 245/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.1103 - accuracy: 0.9647 - val_loss: 1.0914 - val_accuracy: 0.6986\n",
      "Epoch 246/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1128 - accuracy: 0.9644 - val_loss: 1.0293 - val_accuracy: 0.6953\n",
      "Epoch 247/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1124 - accuracy: 0.9622 - val_loss: 1.0703 - val_accuracy: 0.6993\n",
      "Epoch 248/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1112 - accuracy: 0.9626 - val_loss: 1.0583 - val_accuracy: 0.6973\n",
      "Epoch 249/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1192 - accuracy: 0.9619 - val_loss: 0.9626 - val_accuracy: 0.7118\n",
      "Epoch 250/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.1068 - accuracy: 0.9680 - val_loss: 1.0450 - val_accuracy: 0.6973\n",
      "Epoch 251/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1096 - accuracy: 0.9645 - val_loss: 1.0231 - val_accuracy: 0.7058\n",
      "Epoch 252/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1119 - accuracy: 0.9609 - val_loss: 0.9896 - val_accuracy: 0.7045\n",
      "Epoch 253/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.1097 - accuracy: 0.9670 - val_loss: 1.0506 - val_accuracy: 0.7006\n",
      "Epoch 254/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1070 - accuracy: 0.9637 - val_loss: 1.0542 - val_accuracy: 0.6993\n",
      "Epoch 255/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1094 - accuracy: 0.9652 - val_loss: 1.0651 - val_accuracy: 0.6947\n",
      "Epoch 256/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1023 - accuracy: 0.9660 - val_loss: 1.0777 - val_accuracy: 0.6986\n",
      "Epoch 257/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1067 - accuracy: 0.9650 - val_loss: 1.0957 - val_accuracy: 0.6934\n",
      "Epoch 258/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.1072 - accuracy: 0.9660 - val_loss: 1.1371 - val_accuracy: 0.6914\n",
      "Epoch 259/400\n",
      "6090/6090 [==============================] - 4s 591us/step - loss: 0.1143 - accuracy: 0.9640 - val_loss: 1.0696 - val_accuracy: 0.7019\n",
      "Epoch 260/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1121 - accuracy: 0.9631 - val_loss: 1.0608 - val_accuracy: 0.6999\n",
      "Epoch 261/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1114 - accuracy: 0.9657 - val_loss: 1.0835 - val_accuracy: 0.6855\n",
      "Epoch 262/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.1066 - accuracy: 0.9657 - val_loss: 1.1149 - val_accuracy: 0.6868\n",
      "Epoch 263/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.1077 - accuracy: 0.9662 - val_loss: 1.0307 - val_accuracy: 0.6986\n",
      "Epoch 264/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1084 - accuracy: 0.9667 - val_loss: 1.1013 - val_accuracy: 0.6940\n",
      "Epoch 265/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1079 - accuracy: 0.9652 - val_loss: 1.1112 - val_accuracy: 0.6927\n",
      "Epoch 266/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.1021 - accuracy: 0.9677 - val_loss: 1.1093 - val_accuracy: 0.6960\n",
      "Epoch 267/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.1073 - accuracy: 0.9668 - val_loss: 1.0149 - val_accuracy: 0.6947\n",
      "Epoch 268/400\n",
      "6090/6090 [==============================] - 4s 588us/step - loss: 0.1006 - accuracy: 0.9683 - val_loss: 1.1217 - val_accuracy: 0.6953\n",
      "Epoch 269/400\n",
      "6090/6090 [==============================] - 4s 590us/step - loss: 0.0996 - accuracy: 0.9672 - val_loss: 1.1638 - val_accuracy: 0.6907\n",
      "Epoch 270/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.1083 - accuracy: 0.9668 - val_loss: 1.0910 - val_accuracy: 0.6921\n",
      "Epoch 271/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.1021 - accuracy: 0.9665 - val_loss: 1.1482 - val_accuracy: 0.6901\n",
      "Epoch 272/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.1041 - accuracy: 0.9678 - val_loss: 1.1502 - val_accuracy: 0.6947\n",
      "Epoch 273/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1015 - accuracy: 0.9686 - val_loss: 1.1375 - val_accuracy: 0.6875\n",
      "Epoch 274/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1018 - accuracy: 0.9673 - val_loss: 1.1274 - val_accuracy: 0.7019\n",
      "Epoch 275/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.1037 - accuracy: 0.9673 - val_loss: 1.1299 - val_accuracy: 0.6967\n",
      "Epoch 276/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.1038 - accuracy: 0.9677 - val_loss: 1.1485 - val_accuracy: 0.6881\n",
      "Epoch 277/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1035 - accuracy: 0.9667 - val_loss: 1.0721 - val_accuracy: 0.6986\n",
      "Epoch 278/400\n",
      "6090/6090 [==============================] - 4s 588us/step - loss: 0.1050 - accuracy: 0.9644 - val_loss: 1.0921 - val_accuracy: 0.6868\n",
      "Epoch 279/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.0990 - accuracy: 0.9673 - val_loss: 1.1399 - val_accuracy: 0.6993\n",
      "Epoch 280/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1015 - accuracy: 0.9660 - val_loss: 1.1076 - val_accuracy: 0.7019\n",
      "Epoch 281/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.1094 - accuracy: 0.9670 - val_loss: 1.1305 - val_accuracy: 0.6999\n",
      "Epoch 282/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.0948 - accuracy: 0.9685 - val_loss: 1.1767 - val_accuracy: 0.6980\n",
      "Epoch 283/400\n",
      "6090/6090 [==============================] - 4s 588us/step - loss: 0.1003 - accuracy: 0.9667 - val_loss: 1.1623 - val_accuracy: 0.6921\n",
      "Epoch 284/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1024 - accuracy: 0.9667 - val_loss: 1.1068 - val_accuracy: 0.6947\n",
      "Epoch 285/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1055 - accuracy: 0.9634 - val_loss: 1.1244 - val_accuracy: 0.6940\n",
      "Epoch 286/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.0988 - accuracy: 0.9672 - val_loss: 1.1404 - val_accuracy: 0.6953\n",
      "Epoch 287/400\n",
      "6090/6090 [==============================] - 4s 591us/step - loss: 0.0966 - accuracy: 0.9696 - val_loss: 1.1648 - val_accuracy: 0.6934\n",
      "Epoch 288/400\n",
      "6090/6090 [==============================] - 4s 606us/step - loss: 0.0990 - accuracy: 0.9662 - val_loss: 1.1530 - val_accuracy: 0.6999\n",
      "Epoch 289/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.1014 - accuracy: 0.9677 - val_loss: 1.1355 - val_accuracy: 0.7019\n",
      "Epoch 290/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.1003 - accuracy: 0.9665 - val_loss: 1.1471 - val_accuracy: 0.6986\n",
      "Epoch 291/400\n",
      "6090/6090 [==============================] - 4s 589us/step - loss: 0.1052 - accuracy: 0.9652 - val_loss: 1.0471 - val_accuracy: 0.6960\n",
      "Epoch 292/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.1042 - accuracy: 0.9681 - val_loss: 1.0634 - val_accuracy: 0.7131\n",
      "Epoch 293/400\n",
      "6090/6090 [==============================] - 4s 619us/step - loss: 0.1041 - accuracy: 0.9650 - val_loss: 1.1918 - val_accuracy: 0.6907\n",
      "Epoch 294/400\n",
      "6090/6090 [==============================] - 4s 588us/step - loss: 0.1036 - accuracy: 0.9665 - val_loss: 1.1324 - val_accuracy: 0.6953\n",
      "Epoch 295/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.0970 - accuracy: 0.9693 - val_loss: 1.2234 - val_accuracy: 0.6829\n",
      "Epoch 296/400\n",
      "6090/6090 [==============================] - 4s 590us/step - loss: 0.0962 - accuracy: 0.9686 - val_loss: 1.2218 - val_accuracy: 0.6907\n",
      "Epoch 297/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.0982 - accuracy: 0.9678 - val_loss: 1.1789 - val_accuracy: 0.6914\n",
      "Epoch 298/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.0932 - accuracy: 0.9693 - val_loss: 1.2361 - val_accuracy: 0.6763\n",
      "Epoch 299/400\n",
      "6090/6090 [==============================] - 4s 577us/step - loss: 0.0953 - accuracy: 0.9700 - val_loss: 1.2023 - val_accuracy: 0.6940\n",
      "Epoch 300/400\n",
      "6090/6090 [==============================] - 4s 590us/step - loss: 0.0965 - accuracy: 0.9678 - val_loss: 1.1584 - val_accuracy: 0.6907\n",
      "Epoch 301/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.1006 - accuracy: 0.9675 - val_loss: 1.1997 - val_accuracy: 0.6776\n",
      "Epoch 302/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.0968 - accuracy: 0.9678 - val_loss: 1.1933 - val_accuracy: 0.6901\n",
      "Epoch 303/400\n",
      "6090/6090 [==============================] - 4s 593us/step - loss: 0.0984 - accuracy: 0.9640 - val_loss: 1.1101 - val_accuracy: 0.6914\n",
      "Epoch 304/400\n",
      "6090/6090 [==============================] - 4s 599us/step - loss: 0.0990 - accuracy: 0.9681 - val_loss: 1.1719 - val_accuracy: 0.6901\n",
      "Epoch 305/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1024 - accuracy: 0.9662 - val_loss: 1.2194 - val_accuracy: 0.6848\n",
      "Epoch 306/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.0966 - accuracy: 0.9683 - val_loss: 1.1776 - val_accuracy: 0.6901\n",
      "Epoch 307/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.0943 - accuracy: 0.9698 - val_loss: 1.1978 - val_accuracy: 0.6973\n",
      "Epoch 308/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.0931 - accuracy: 0.9675 - val_loss: 1.2126 - val_accuracy: 0.6914\n",
      "Epoch 309/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.0953 - accuracy: 0.9690 - val_loss: 1.2108 - val_accuracy: 0.6842\n",
      "Epoch 310/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.0949 - accuracy: 0.9683 - val_loss: 1.2034 - val_accuracy: 0.6901\n",
      "Epoch 311/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.0985 - accuracy: 0.9681 - val_loss: 1.1683 - val_accuracy: 0.6894\n",
      "Epoch 312/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.0937 - accuracy: 0.9678 - val_loss: 1.2837 - val_accuracy: 0.6724\n",
      "Epoch 313/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.1011 - accuracy: 0.9675 - val_loss: 1.2784 - val_accuracy: 0.6927\n",
      "Epoch 314/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.1022 - accuracy: 0.9649 - val_loss: 1.1550 - val_accuracy: 0.6894\n",
      "Epoch 315/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.0946 - accuracy: 0.9690 - val_loss: 1.2198 - val_accuracy: 0.6901\n",
      "Epoch 316/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.0959 - accuracy: 0.9685 - val_loss: 1.1761 - val_accuracy: 0.6815\n",
      "Epoch 317/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.0953 - accuracy: 0.9693 - val_loss: 1.1098 - val_accuracy: 0.6927\n",
      "Epoch 318/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.0929 - accuracy: 0.9685 - val_loss: 1.2512 - val_accuracy: 0.6901\n",
      "Epoch 319/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.0949 - accuracy: 0.9677 - val_loss: 1.1290 - val_accuracy: 0.6855\n",
      "Epoch 320/400\n",
      "6090/6090 [==============================] - 4s 578us/step - loss: 0.0974 - accuracy: 0.9700 - val_loss: 1.2125 - val_accuracy: 0.6888\n",
      "Epoch 321/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.0939 - accuracy: 0.9681 - val_loss: 1.2000 - val_accuracy: 0.6888\n",
      "Epoch 322/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.0928 - accuracy: 0.9693 - val_loss: 1.1569 - val_accuracy: 0.6980\n",
      "Epoch 323/400\n",
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.0944 - accuracy: 0.9695 - val_loss: 1.1760 - val_accuracy: 0.6901\n",
      "Epoch 324/400\n",
      "6090/6090 [==============================] - 4s 590us/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 1.2075 - val_accuracy: 0.6894\n",
      "Epoch 325/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.1005 - accuracy: 0.9668 - val_loss: 1.0735 - val_accuracy: 0.6914\n",
      "Epoch 326/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.0891 - accuracy: 0.9701 - val_loss: 1.1790 - val_accuracy: 0.6934\n",
      "Epoch 327/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.0901 - accuracy: 0.9680 - val_loss: 1.2010 - val_accuracy: 0.6914\n",
      "Epoch 328/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.0933 - accuracy: 0.9696 - val_loss: 1.2559 - val_accuracy: 0.6914\n",
      "Epoch 329/400\n",
      "6090/6090 [==============================] - 4s 589us/step - loss: 0.0906 - accuracy: 0.9698 - val_loss: 1.2337 - val_accuracy: 0.6861\n",
      "Epoch 330/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090/6090 [==============================] - 4s 579us/step - loss: 0.0915 - accuracy: 0.9690 - val_loss: 1.2432 - val_accuracy: 0.6894\n",
      "Epoch 331/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.0911 - accuracy: 0.9704 - val_loss: 1.2222 - val_accuracy: 0.6927\n",
      "Epoch 332/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.0953 - accuracy: 0.9691 - val_loss: 1.1959 - val_accuracy: 0.6907\n",
      "Epoch 333/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.0896 - accuracy: 0.9700 - val_loss: 1.2819 - val_accuracy: 0.6960\n",
      "Epoch 334/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.0940 - accuracy: 0.9696 - val_loss: 1.2171 - val_accuracy: 0.6848\n",
      "Epoch 335/400\n",
      "6090/6090 [==============================] - 4s 589us/step - loss: 0.0912 - accuracy: 0.9688 - val_loss: 1.1946 - val_accuracy: 0.6927\n",
      "Epoch 336/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.0912 - accuracy: 0.9708 - val_loss: 1.2876 - val_accuracy: 0.6875\n",
      "Epoch 337/400\n",
      "6090/6090 [==============================] - 4s 595us/step - loss: 0.0948 - accuracy: 0.9703 - val_loss: 1.2442 - val_accuracy: 0.6763\n",
      "Epoch 338/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.0928 - accuracy: 0.9708 - val_loss: 1.1832 - val_accuracy: 0.6921\n",
      "Epoch 339/400\n",
      "6090/6090 [==============================] - 4s 583us/step - loss: 0.0884 - accuracy: 0.9718 - val_loss: 1.3029 - val_accuracy: 0.6796\n",
      "Epoch 340/400\n",
      "6090/6090 [==============================] - 4s 594us/step - loss: 0.0906 - accuracy: 0.9691 - val_loss: 1.2793 - val_accuracy: 0.6855\n",
      "Epoch 341/400\n",
      "6090/6090 [==============================] - 4s 593us/step - loss: 0.0863 - accuracy: 0.9708 - val_loss: 1.2473 - val_accuracy: 0.6921\n",
      "Epoch 342/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.0899 - accuracy: 0.9700 - val_loss: 1.2751 - val_accuracy: 0.6861\n",
      "Epoch 343/400\n",
      "6090/6090 [==============================] - 4s 594us/step - loss: 0.0856 - accuracy: 0.9704 - val_loss: 1.3022 - val_accuracy: 0.6855\n",
      "Epoch 344/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.0883 - accuracy: 0.9696 - val_loss: 1.2700 - val_accuracy: 0.6868\n",
      "Epoch 345/400\n",
      "6090/6090 [==============================] - 4s 590us/step - loss: 0.0849 - accuracy: 0.9706 - val_loss: 1.2503 - val_accuracy: 0.6927\n",
      "Epoch 346/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.0930 - accuracy: 0.9665 - val_loss: 1.2130 - val_accuracy: 0.6914\n",
      "Epoch 347/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.0869 - accuracy: 0.9704 - val_loss: 1.3271 - val_accuracy: 0.6875\n",
      "Epoch 348/400\n",
      "6090/6090 [==============================] - 4s 581us/step - loss: 0.0929 - accuracy: 0.9693 - val_loss: 1.2463 - val_accuracy: 0.6881\n",
      "Epoch 349/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.0857 - accuracy: 0.9703 - val_loss: 1.3377 - val_accuracy: 0.6815\n",
      "Epoch 350/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.0871 - accuracy: 0.9718 - val_loss: 1.2495 - val_accuracy: 0.6875\n",
      "Epoch 351/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.0881 - accuracy: 0.9696 - val_loss: 1.2837 - val_accuracy: 0.6875\n",
      "Epoch 352/400\n",
      "6090/6090 [==============================] - 4s 596us/step - loss: 0.0929 - accuracy: 0.9695 - val_loss: 1.3096 - val_accuracy: 0.6815\n",
      "Epoch 353/400\n",
      "6090/6090 [==============================] - 4s 586us/step - loss: 0.0861 - accuracy: 0.9686 - val_loss: 1.3696 - val_accuracy: 0.6842\n",
      "Epoch 354/400\n",
      "6090/6090 [==============================] - 4s 582us/step - loss: 0.0897 - accuracy: 0.9695 - val_loss: 1.2716 - val_accuracy: 0.6875\n",
      "Epoch 355/400\n",
      "6090/6090 [==============================] - 4s 591us/step - loss: 0.0884 - accuracy: 0.9700 - val_loss: 1.2977 - val_accuracy: 0.6848\n",
      "Epoch 356/400\n",
      "6090/6090 [==============================] - 4s 587us/step - loss: 0.0878 - accuracy: 0.9698 - val_loss: 1.2460 - val_accuracy: 0.6881\n",
      "Epoch 357/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.0915 - accuracy: 0.9708 - val_loss: 1.2143 - val_accuracy: 0.6881\n",
      "Epoch 358/400\n",
      "6090/6090 [==============================] - 4s 584us/step - loss: 0.0894 - accuracy: 0.9675 - val_loss: 1.2928 - val_accuracy: 0.6855\n",
      "Epoch 359/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.0889 - accuracy: 0.9711 - val_loss: 1.2217 - val_accuracy: 0.6861\n",
      "Epoch 360/400\n",
      "6090/6090 [==============================] - 4s 588us/step - loss: 0.0835 - accuracy: 0.9713 - val_loss: 1.2798 - val_accuracy: 0.6848\n",
      "Epoch 361/400\n",
      "6090/6090 [==============================] - 4s 585us/step - loss: 0.0827 - accuracy: 0.9718 - val_loss: 1.3264 - val_accuracy: 0.6875\n",
      "Epoch 362/400\n",
      "6090/6090 [==============================] - 4s 588us/step - loss: 0.0873 - accuracy: 0.9695 - val_loss: 1.2666 - val_accuracy: 0.6783\n",
      "Epoch 363/400\n",
      "6090/6090 [==============================] - 4s 588us/step - loss: 0.0838 - accuracy: 0.9700 - val_loss: 1.2754 - val_accuracy: 0.6868\n",
      "Epoch 364/400\n",
      "6090/6090 [==============================] - 4s 613us/step - loss: 0.0899 - accuracy: 0.9704 - val_loss: 1.3320 - val_accuracy: 0.6881\n",
      "Epoch 365/400\n",
      "6090/6090 [==============================] - 4s 638us/step - loss: 0.0879 - accuracy: 0.9704 - val_loss: 1.2944 - val_accuracy: 0.6776\n",
      "Epoch 366/400\n",
      "6090/6090 [==============================] - 5s 891us/step - loss: 0.0846 - accuracy: 0.9711 - val_loss: 1.3072 - val_accuracy: 0.6861\n",
      "Epoch 367/400\n",
      "6090/6090 [==============================] - 5s 826us/step - loss: 0.0890 - accuracy: 0.9700 - val_loss: 1.2801 - val_accuracy: 0.6815\n",
      "Epoch 368/400\n",
      "6090/6090 [==============================] - 5s 837us/step - loss: 0.0863 - accuracy: 0.9718 - val_loss: 1.3268 - val_accuracy: 0.6848\n",
      "Epoch 369/400\n",
      "6090/6090 [==============================] - 5s 800us/step - loss: 0.0840 - accuracy: 0.9719 - val_loss: 1.2667 - val_accuracy: 0.6868\n",
      "Epoch 370/400\n",
      "6090/6090 [==============================] - 4s 700us/step - loss: 0.0865 - accuracy: 0.9714 - val_loss: 1.3174 - val_accuracy: 0.6848\n",
      "Epoch 371/400\n",
      "6090/6090 [==============================] - 5s 756us/step - loss: 0.0809 - accuracy: 0.9721 - val_loss: 1.4406 - val_accuracy: 0.6855\n",
      "Epoch 372/400\n",
      "6090/6090 [==============================] - 4s 727us/step - loss: 0.0850 - accuracy: 0.9704 - val_loss: 1.3331 - val_accuracy: 0.6888\n",
      "Epoch 373/400\n",
      "6090/6090 [==============================] - 5s 786us/step - loss: 0.0847 - accuracy: 0.9695 - val_loss: 1.3444 - val_accuracy: 0.6815\n",
      "Epoch 374/400\n",
      "6090/6090 [==============================] - 4s 665us/step - loss: 0.0848 - accuracy: 0.9708 - val_loss: 1.3377 - val_accuracy: 0.6809\n",
      "Epoch 375/400\n",
      "6090/6090 [==============================] - 3s 571us/step - loss: 0.0868 - accuracy: 0.9698 - val_loss: 1.3081 - val_accuracy: 0.6881\n",
      "Epoch 376/400\n",
      "6090/6090 [==============================] - 3s 571us/step - loss: 0.0853 - accuracy: 0.9703 - val_loss: 1.3011 - val_accuracy: 0.6861\n",
      "Epoch 377/400\n",
      "6090/6090 [==============================] - 3s 561us/step - loss: 0.0852 - accuracy: 0.9696 - val_loss: 1.3463 - val_accuracy: 0.6881\n",
      "Epoch 378/400\n",
      "6090/6090 [==============================] - 3s 562us/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 1.3858 - val_accuracy: 0.6835\n",
      "Epoch 379/400\n",
      "6090/6090 [==============================] - 3s 558us/step - loss: 0.0819 - accuracy: 0.9726 - val_loss: 1.3592 - val_accuracy: 0.6881\n",
      "Epoch 380/400\n",
      "6090/6090 [==============================] - 3s 561us/step - loss: 0.0813 - accuracy: 0.9716 - val_loss: 1.3488 - val_accuracy: 0.6881\n",
      "Epoch 381/400\n",
      "6090/6090 [==============================] - 3s 562us/step - loss: 0.0791 - accuracy: 0.9721 - val_loss: 1.4094 - val_accuracy: 0.6842\n",
      "Epoch 382/400\n",
      "6090/6090 [==============================] - 3s 559us/step - loss: 0.0845 - accuracy: 0.9721 - val_loss: 1.2925 - val_accuracy: 0.6875\n",
      "Epoch 383/400\n",
      "6090/6090 [==============================] - 3s 562us/step - loss: 0.0807 - accuracy: 0.9714 - val_loss: 1.3392 - val_accuracy: 0.6875\n",
      "Epoch 384/400\n",
      "6090/6090 [==============================] - 3s 562us/step - loss: 0.0865 - accuracy: 0.9700 - val_loss: 1.3552 - val_accuracy: 0.6875\n",
      "Epoch 385/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090/6090 [==============================] - 3s 556us/step - loss: 0.0794 - accuracy: 0.9727 - val_loss: 1.4635 - val_accuracy: 0.6770\n",
      "Epoch 386/400\n",
      "6090/6090 [==============================] - 4s 580us/step - loss: 0.0832 - accuracy: 0.9721 - val_loss: 1.4146 - val_accuracy: 0.6691\n",
      "Epoch 387/400\n",
      "6090/6090 [==============================] - 3s 566us/step - loss: 0.0854 - accuracy: 0.9711 - val_loss: 1.3554 - val_accuracy: 0.6855\n",
      "Epoch 388/400\n",
      "6090/6090 [==============================] - 3s 558us/step - loss: 0.0800 - accuracy: 0.9716 - val_loss: 1.3923 - val_accuracy: 0.6855\n",
      "Epoch 389/400\n",
      "6090/6090 [==============================] - 3s 559us/step - loss: 0.0857 - accuracy: 0.9722 - val_loss: 1.3859 - val_accuracy: 0.6724\n",
      "Epoch 390/400\n",
      "6090/6090 [==============================] - 3s 560us/step - loss: 0.0839 - accuracy: 0.9711 - val_loss: 1.3889 - val_accuracy: 0.6822\n",
      "Epoch 391/400\n",
      "6090/6090 [==============================] - 3s 561us/step - loss: 0.0827 - accuracy: 0.9729 - val_loss: 1.2924 - val_accuracy: 0.6822\n",
      "Epoch 392/400\n",
      "6090/6090 [==============================] - 3s 557us/step - loss: 0.0781 - accuracy: 0.9722 - val_loss: 1.4295 - val_accuracy: 0.6789\n",
      "Epoch 393/400\n",
      "6090/6090 [==============================] - 3s 572us/step - loss: 0.0804 - accuracy: 0.9693 - val_loss: 1.3488 - val_accuracy: 0.6848\n",
      "Epoch 394/400\n",
      "6090/6090 [==============================] - 3s 567us/step - loss: 0.0834 - accuracy: 0.9711 - val_loss: 1.3446 - val_accuracy: 0.6822\n",
      "Epoch 395/400\n",
      "6090/6090 [==============================] - 3s 556us/step - loss: 0.0783 - accuracy: 0.9726 - val_loss: 1.4246 - val_accuracy: 0.6789\n",
      "Epoch 396/400\n",
      "6090/6090 [==============================] - 3s 558us/step - loss: 0.0803 - accuracy: 0.9714 - val_loss: 1.4199 - val_accuracy: 0.6822\n",
      "Epoch 397/400\n",
      "6090/6090 [==============================] - 3s 560us/step - loss: 0.0790 - accuracy: 0.9724 - val_loss: 1.4407 - val_accuracy: 0.6776\n",
      "Epoch 398/400\n",
      "6090/6090 [==============================] - 3s 557us/step - loss: 0.0803 - accuracy: 0.9724 - val_loss: 1.4063 - val_accuracy: 0.6829\n",
      "Epoch 399/400\n",
      "6090/6090 [==============================] - 3s 566us/step - loss: 0.0798 - accuracy: 0.9732 - val_loss: 1.5463 - val_accuracy: 0.6717\n",
      "Epoch 400/400\n",
      "6090/6090 [==============================] - 3s 561us/step - loss: 0.0900 - accuracy: 0.9695 - val_loss: 1.3461 - val_accuracy: 0.6756\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_t, target, epochs=400, batch_size=100, validation_split=0.2)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Submission Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf MNB and RF submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length_of_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword location                                               text  \\\n",
       "0  earthquake      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1         NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2         NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3         NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4         NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  length_of_tweet  \n",
       "0       1               69  \n",
       "1       1               38  \n",
       "2       1              133  \n",
       "3       1               65  \n",
       "4       1               88  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data_train2 = vectorizer2.fit_transform(df.text)\n",
    "\n",
    "tf_idf_data_test2 = vectorizer2.transform(test_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier2 = MultinomialNB()\n",
    "\n",
    "nb_classifier2.fit(tf_idf_data_train2, df.target)\n",
    "nb_train_preds2 = nb_classifier2.predict(tf_idf_data_train2)\n",
    "nb_test_preds2 = nb_classifier2.predict(tf_idf_data_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier2 = RandomForestClassifier(criterion='entropy', max_depth=None, min_samples_leaf=3, min_samples_split=10, n_estimators=150)\n",
    "\n",
    "rf_classifier2.fit(tf_idf_data_train2, df.target)\n",
    "rf_train_preds2 = rf_classifier2.predict(tf_idf_data_train2)\n",
    "rf_test_preds2 = rf_classifier2.predict(tf_idf_data_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = rf_test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-e132bd05d567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4176\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4178\u001b[0;31m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4179\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4180\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "sample_submission.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN w/ word embeddings submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_test = text.Tokenizer(num_words=500)\n",
    "tokenizer_test.fit_on_texts(list(test_df.text))\n",
    "list_tokenized_tweets_test = tokenizer_test.texts_to_sequences(test_df.text)\n",
    "testX_t = sequence.pad_sequences(list_tokenized_tweets_test, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = model.predict(testX_t)\n",
    "\n",
    "y_classes = nn_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target\n",
       "id        \n",
       "0        1\n",
       "2        0\n",
       "3        0\n",
       "9        0\n",
       "11       0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission1.target = y_classes\n",
    "sample_submission1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission1.to_csv('submission1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
